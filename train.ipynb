{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional_Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZm3k_JwAxFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oX6ISEIaA5k",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKcBS6xfBK1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((32,32)),\n",
        "                               #transforms.Grayscale(),\n",
        "                               transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=1),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,))\n",
        "                               ])\n",
        "\n",
        "training_dataset = datasets.SVHN(root='./data', download=True, split='train', transform=transform)\n",
        "validation_dataset = datasets.SVHN(root='./data', download=True, split='test', transform=transform)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size =100, shuffle=False)\n",
        "\n",
        "def convert_image(tensor):\n",
        "  image = tensor.cpu().clone().detach().numpy()\n",
        "  image = image.transpose(1, 2, 0)\n",
        "  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
        "  image = image.clip(0, 1)\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELDFsBKeHqJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 60, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(60, 150, 5, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(5*5*150, 500)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        \n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "\n",
        "        x = x.view(-1, 5*5*150)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsd3HPylP9UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LeNet().to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)\n",
        "epochs = 150\n",
        "\n",
        "training_loss_history = []\n",
        "training_corrects_history = []\n",
        "validation_loss_history = []\n",
        "validation_corrects_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  training_loss = 0.0\n",
        "  training_correct = 0.0\n",
        "  validation_loss = 0.0\n",
        "  validation_correct = 0.0\n",
        "  \n",
        "  for inputs, labels in training_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_func(outputs, labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    training_loss += loss.item()\n",
        "    training_correct += torch.sum(preds == labels.data)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for val_inputs, val_labels in validation_loader:\n",
        "      val_inputs = val_inputs.to(device)\n",
        "      val_labels = val_labels.to(device)\n",
        "      val_outputs = model(val_inputs)\n",
        "      val_loss = loss_func(val_outputs, val_labels)\n",
        "      \n",
        "      _, val_preds = torch.max(val_outputs, 1)\n",
        "      validation_loss += val_loss.item()\n",
        "      validation_correct += torch.sum(val_preds == val_labels.data)\n",
        "      \n",
        "    epoch_loss = training_loss/len(training_loader)\n",
        "    epoch_acc = training_correct.float()/ len(training_loader)\n",
        "\n",
        "    training_loss_history.append(epoch_loss)\n",
        "    training_corrects_history.append(epoch_acc)\n",
        "    \n",
        "    val_epoch_loss = validation_loss/len(validation_loader)\n",
        "    val_epoch_acc = validation_correct.float()/ len(validation_loader)\n",
        "    validation_loss_history.append(val_epoch_loss)\n",
        "    validation_corrects_history.append(val_epoch_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq4-LouHVQwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(training_loss_history, label='training loss')\n",
        "plt.plot(validation_loss_history, label='validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1A-fOideMnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(training_corrects_history, label='training accuracy')\n",
        "plt.plot(validation_corrects_history, label='validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE7haDIMG2cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Iterator = iter(validation_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "output = model(images)\n",
        "_, preds = torch.max(output, 1)\n",
        "\n",
        "fig = plt.figure(figsize=(30, 4))\n",
        "\n",
        "for ndx in np.arange(20):\n",
        "  img = fig.add_subplot(2, 10, ndx+1, xticks=[], yticks=[])\n",
        "  plt.imshow(im_convert(images[ndx]))\n",
        "  img.set_title(\"{} ({})\".format(str(preds[ndx].item()), str(labels[ndx].item())), color=(\"green\" if preds[ndx]==labels[ndx] else \"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzLUhaxBIHwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), \"digit_classification_cnn.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T_ZrUw7uJpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': 'digit_classification_cnn.pt'})\n",
        "uploaded.SetContentFile('digit_classification_cnn.pt')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}